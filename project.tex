\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\newcommand{\del}{\nabla}
\doublespacing
\begin{document}

\title{Nonlinear Analysis of VR Synchronization}
\author{Howon Lee}
\maketitle

\section{Abstract}
There exists a literature dealing with time series analysis in the nonlinear sciences in the case of synchronization, or the adjustment of rhythms of oscillating objects to coincide with each other due to weak interaction. We attempt many of these methods in analyzing an instance of the phenomenon of interpersonal synchrony in a virtual environment.%%% We also propose a mapping from time series to networks with a deterministic inverse.

%%% acknowledgements go here

%%% target is JB, ASW, SG, each of them at once
%%% examples should abound, and should be explicated

\section{Introduction}

%%%% here, citation means read em again and think about them and expand a little bit, and _then_ cite and poke around

Before defining what we mean by synchronization in this context, we note that there exists a long history of the study of synchronization outside of social science. Synchronization was first reported in physical systems by Huygens in 1665. He saw that two pendulum clocks in the boat that he was testing the clocks in were mysteriously ticking in unison, and found that the cause was a support beam which connected the clocks, which moved imperceptibly and therefore maintained the synchronization. %% cite for history of huygen's synchronization paper

Centuries later, the physical and biological systems which were later found to synchronize include mechanical rotators, lasers, fireflies emitting synchronous patterns of light, synchronous contraction of heart cells, synchronization of human circadian rhythm to a solar light cycle, and synchronous interaction of human beings. %%%cite synchronization review, sync papers for all those things

Now, we should define the terms. Interpersonal synchrony is defined in the social science literature as individuals' termporal coordination during social interaction. In the physical sciences, synchronization is defined as an adjustment of rhythms of oscillating objects due to weak interaction, with generalizations possible for chaotic systems, which depend upon a phase of the chaotic system existing. %%% cite social psych, physics definition of synchronization

Although social synchrony is one of many other synchronies, many of which do not necessarily serve a function of any kind, it is observed that social synchrony serves a function in human social groups. There exists evidence that synchronization acts as a cooperation-enducing mechanism, that it acts to induce rapport, and that it in actuality, independent of its effect on rapport, enhances the ability to pursue joint goals in tandem for those who are synchronized. This suggests immediately that it must be measured in a systematic way, to study phenomena of that kind. %%% cite for cooperation enducing mechanism, inducing rapport, enhancing the ability to pursue joint goals

In the beginning of the social synchronization literature, most psychologists did not used the then-developing automated signals processing techniques for the detection and measurement of synchronization, instead using manual methods to detect and rate the presence or absence of synchronization, with trained raters and validated measuring systems. Although these measurements have been validated, they depend upon human raters and therefore are less replicable and less convenient than automated systems. %%% cite some of those non-automated systems

Given that the signals created by an individual during social interaction have a phase, and social interaction can be construed as a weak interaction between the two individual systems, it should be clear that the definition of interpersonal synchrony given in the social psychological literature is a subset of the definition given in the physics literature. This has often been noted, and has therefore spawned a cross-disciplinary field wherein signals processing techniques are used to measure interpersonal synchrony. %%% cite the reviews of this thing

As a specific instance of a domain where signals processing techniques are used, a large problem in synchronization is the definition of the signal itself and its extraction from observations of social interaction. To this end, many methods have been used, including extraction of coordination of movement features and speech features, movement of single and dyadic body parts, image processing techniques and video tracking techniques. %%% cite a bunch of stuff taken from delaherche cohen paper and my own lit stuff

An important analogy exists between the collection of time series data about the physiology of the body in order to assess synchrony and the collection of time series data about the body in order to assess health. Indeed, there exists a literature on the synchronization properties and the time series analysis of heart rate variability which we have derived much inspiration from, not necessarily in the usage of correlational metrics, for which there is a literature dealing in social synchronization, but more sophisticated metrics for which there is not such a literature. The essential premise is that we treat social synchronization as an instance of an abstract problem of physical synchronization, which justifies using measures used by other physiological measurements.%%% cite some heart rate variability papers

%%% those techniques have a problem, VR is cool kids way of doing it

%%% experimental control versus ecological validity: but you don't have to choose between the tool, you can escape the lab in a controlled setting with virutal reality. naturalistic vision of vistas and scenes, naturalistic ability to interact socially, although I think this condition was mixed media. really great data collection %%% cite blascovich and beall "basic research tool in psych" paper
This project will attempt to use some of the already existing tools for the analysis of time series data on VR time series data, as well as apply some tools which have not previously been used to analyze synchronization in VR time series data of social synchronization in a virtual world.
%%% summary of what exists, talk only about the fact that they exist, as a preliminary summary of the essay. we will go deeper and actually formal with this one
%%% correlation (time-lagged cross-correlation), recurrence analysis
%%% review MI method in physics literature.
%%% spectral methods, analytic signal idea
%%% graphs



%%% describe the data that we got, data from Andrea's stuff basically, maybe the new coding.
%%% problems: missing data
%%% another wonky thing: the ad hoc reductions made, just see Andrea's stuff here

\section{Time Domain Analysis}

\subsection{Correlation Analysis}

%%% definition of what the time series is in the time domain
%%% description of the preprocessing mess done on it

%%% what are the correlations, mathematically? what are correlations in general, mathematically? autocorrelation? cross-correlation?

%%% poincare maps go here I guess

%%% what are the cornettos? why the cornettos? what are they mathematically?
Correlation and the cornettos go here. Talk about benefits and detriments of the cornetto stuff

One analysis commonly used with relaxation oscillators like ECG data is the Poincare map, not to be confused with the Poincare plot. However, because there are not clear demarcations as to where each oscillation is, the Poincare map is less suited to this dataset and will not be used. %%% cite for Poincare map
%% what's the essential linearity problem with correlational analysis?

\subsection{Mutual Information Analysis}

The main limitation of cross-correlational analysis of time series is that it is fundamentally linear. That is, the dependences which the correlation function can capture are linear in nature. It is possible to learn about higher order dependences if correlations of higher moments are used, but this becomes rapidly time-consuming very quickly. %% cite pompe paper.

%%%% the sine relation example goes here, showing that correlation is not good

In order to introduce mutual information, we must introduce Shannon information and Shannon entropy.

Shannon information is defined on a measurement drawn from some set (let the set be discrete, $X \in {1 ... n}$, for ease of notation: there exist continuous analogues). Given that measurement from some set, the Shannon information in bits is defined as:

$$ -\log_2 P_X(i) $$

where $P_X(i)$ is the probability that a measurement will find the system in state $i$. That is, a lower probability answer is more surprising, and therefore more information is found in it.

Shannon entropy, denoted $H(X)$ is defined on a data stream (a measurement stream) $X$. It is the average amount of information contained in every message received, and so is also measured in bits. An easy intuition about entropy can be gained by noting that a \emph{fair} coin flipping process is the most entropic possible coin flip, because we are most surprised by it. Formally, entropy is:

$$H(X) = -\sum_i P_X(i) \log_2 P_X(i)$$

Information and entropy are also defined on joint probability distributions in an analogous way. The information of a joint probability distribution on variables $X$ and $Y$ is:

$$ -\log_2 P_{XY}(i, j) $$

And the entropy, therefore, is:

$$H(X, Y) = -\sum_i \sum_j P_{XY}(i, j) log_2 P_{XY}(i, j)$$

Now, if we sample two random variables simultaneously, the relationship has a quantity defined upon it which is called the \emph{mutual information}. Because it is defined on the relation, it has an auto-mutual information variant and a cross-mutual information variant, like correlation does. However, mutual information measures something different, which is the \emph{information which one of the random variables gives me about the other random variable}. It is defined as:

$$I(X, Y) = H(X) + H(Y) - H(X, Y)$$

And one sees that this quantity is symmetric with respect to $X$ and $Y$.

\subsubsection{AMI and CMI}

Auto-mutual information (AMI) and cross mutual information(CMI) are the mutual information analogues to autocorrelation and cross-correlation. They have the same advantages over the correlation variants as mutual information itself has to correlation. Therefore, they are better measurements for synchronization.

%%% put in a bunch of stuff for MI in physiological data
Mutual information analysis goes here. So does a KS entropy analysis

%%% and then we go to our data

\section{Frequency Domain Analysis}

There is more than one way to represent time series data, even given only the data itself and not any underlying function that generates it. The most important alternate representation is the frequency domain representation, which is taken in finite data with the discrete Fourier transform. Later, we will show the use of the frequency representation in re-representing our data so that it shows a numerical current state of the phase, using the related Hilbert transform.

The frequency domain represents data in terms of the linear combination of simple sine and cosine waves: the analogy often used is that of a chord being hit on a piano, which can be represented with its time domain signal but can also be represented as the amplitude of the individual notes within the chord, which presents a better decomposition of the sound in and of itself. Likewise, we can attempt to decompose our time domain signals into the frequencies of the sinusoids which make it up.

The discrete fourier transform is an essential tool for the further analyses below. It converts a finite discrete sample from the time to the frequency domain in a computable and fast way.

%%% short section on math of dft. why is it a _transform_? (aka, show that math). what is power spectrum? what is the relation to the autocorrelation?

%%% other people have used spectral methods.

%%% why use coherence instead of other measures?

\subsection{Hilbert Transform and $\gamma$}

A signal is called an \emph{analytic signal} if it does not have any negative-frequency components. The Hilbert transform is a way to get the analytic \emph{representation} for a signal in the time domain, which throws away the superfluous information which would be in a spectrum of that signal. This allows the expression of the analytic signal in terms of its time-variant magnitude and phase, allowing a study of the phase in an \emph{unwrapped form}. %%% cite gabor 1946

Formally speaking, given that the original signal is $s(t)$, the analytic signal $\zeta$ is:

$$\zeta(t) = s(t) + js_H(t) = A(t)e^{j\phi(t)}$$

$$s_H(t) = \frac{1}{\pi} PV \int_{-\infty}^{\infty} \frac{s(t)}{t - \tau} d\tau$$

$s_H$ is called the Hilbert transform; $PV$ indicates that the integral is a Cauchy principal value integral. The Hilbert transform is thus formally equivalent to convolution of $s(t)$ with $\frac{1}{\pi t}$, so it can easily be calculated from the fast Fourier transform.

%%% finish the formalism

%%% pretty picture of unwrapped hilbert transform for toy function
%%% why use hilbert transform instead of other measrues?

%%%% do the phase difference measure

%%%What's gamma? Why gamma?

%%%Why use this one over poincare map? Why would it be more durable?

\section{Deterministic dual between discrete time series and ordered multigraph}

\subsection{Description}

%%% define discrete time series more clearly
There exists a line of analysis in the complex network literature which aims to convert a discrete or discretized time series into a network. This is advantageous for analysis of time series because there is a deep and well-developed theory of networks: so far, an important result is that different time series result in networks with distinct topological properties, and that these topological properties relate to the time series in some way in addition to being determined by them. %%% cite the campanharo dual network paper
%%%% cite and quickly describe visibility graph, spectral methods, recurrence graph, other stuff

Upon hearing of the mapping from a time series into a network, it might be wondered at if there exists a mapping from a network back into a time series. There does exist some methods to apply the inverse mapping, but none of these are deterministic, meaning that the network topology constrains the set of time series that the mapping can produce from that network, but does not completely determine it. Therefore, it cannot be said that the mapping from time series to networks or back is properly a \emph{transform}.%%% again the campanharo dual network paper

A deterministic transformation from time series to networks and from networks to time series can be made, however, if we allow duplication in the adjacencies of each vertex of the graph (making the graph a multigraph, by many definitions of multigraph), and if we keep the order in which the vertices were travelled in the discrete time series. In addition to this, the start state of the time series must be stored.

In order to construct the labelled multigraph from a time series, the possible states of the time series, $\Sigma = {1 ... N}$ are made into the vertices of the multigraph. Then, starting with the value of the series at $t =1$, the vertices are traversed in the order that the corresponding states are traversed in the time series, and when one leaves a vertex $V_1$ to go to a vertex $V_2$, the identity of $V_2$ is pushed onto the list (like a stack) for the adjacencies of $V_1$.

In order to reconstruct the time series from a multigraph of this kind, therefore, we start from the start node again and consume the adjacency lists starting from the initial elements of the lists, to find the next node to jump to.

%%%% picture would be nice here

%%% mention pushdown automata here, pumping lemma related

%%% two uses: apply graph theory, do deterministic resampling

\subsection{Toy Model}

%Recreate the time series of logistic map here.

% recreate time series of representative time thing here
%
%Note tha time series resampling is now possible deterministically. Talk about the time series resampling.

\subsection{Real Data}

%Now, do complex network analysis things with the VR data and with logistic map.

\begin{thebibliography}{}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\end{thebibliography}

\end{document}
